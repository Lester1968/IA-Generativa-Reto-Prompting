# âœï¸ Reto 2 â€“ Mejorando la ComunicaciÃ³n con un LLM mediante Prompting

**Curso:** Usos Profesionales de la IA Generativa â€“ IBM SkillsBuild (2025)  
**Autor:** Lester DÃ¡vila

---

## ğŸ¯ Objetivo

Explorar cÃ³mo la formulaciÃ³n del prompt afecta la precisiÃ³n, claridad y calidad de las respuestas generadas por un Large Language Model (LLM). Se aplica la tÃ©cnica **Chain of Thought Prompting** para transformar un ejemplo ambiguo en una consulta clara y lÃ³gica.

---

## ğŸ” AnÃ¡lisis del Prompt Inicial

### âŒ Prompt Zero-Shot

> â€œCalcula cuÃ¡ntas frutas hay en total: Tengo 3 manzanas y compro 2 cajas de peras con 4 peras cada una.â€

### ğŸ” Posibles fallos:

- No induce razonamiento paso a paso.
- Puede omitir multiplicaciÃ³n implÃ­cita.
- Riesgo de alucinaciÃ³n por ambigÃ¼edad.

ğŸ‘‰ Los LLMs predicen texto, no "razonan" como humanos. Si no se guÃ­a su estructura, puede fallar el cÃ¡lculo.

---

## ğŸ› ï¸ TÃ©cnica aplicada: Chain of Thought Prompting (CoT)

La tÃ©cnica **Chain of Thought (Cadena de Pensamiento)** instruye explÃ­citamente al modelo para **razonar paso a paso**, ideal en tareas que requieren lÃ³gica, explicaciÃ³n o precisiÃ³n matemÃ¡tica.

---

## âœ… Prompt Mejorado (CoT)

> â€œCalcula cuÃ¡ntas frutas hay en total. Razona paso a paso antes de dar la respuesta final.  
Tengo 3 manzanas y compro 2 cajas de peras. Cada caja tiene 4 peras.â€

---

## ğŸ“ˆ ComparaciÃ³n de enfoques

| Criterio                   | Zero-Shot Prompt                     | Prompt con CoT                        |
|---------------------------|--------------------------------------|---------------------------------------|
| Razonamiento inducido     | No                                   | SÃ­ (paso a paso)                      |
| InterpretaciÃ³n numÃ©rica   | ImplÃ­cita                            | ExplÃ­cita                             |
| Transparencia de lÃ³gica   | Baja                                 | Alta                                  |
| Riesgo de error o invenciÃ³n| Alto                                 | Bajo                                  |

---

## ğŸ§© Resultado Esperado del LLM

```
Paso 1: Tengo 3 manzanas.  
Paso 2: Compro 2 cajas de peras.  
Paso 3: Cada caja tiene 4 peras â†’ 2 Ã— 4 = 8 peras.  
Paso 4: Total = 3 + 8 = **11 frutas**
```

---

## ğŸ§  ConclusiÃ³n

Este reto demuestra que una estrategia de prompting bien aplicada puede transformar la calidad de las respuestas de un LLM. La tÃ©cnica **Chain of Thought**:
- Mejora la precisiÃ³n del modelo.
- Aumenta la claridad explicativa.
- Reduce alucinaciones y ambigÃ¼edad.

> En contextos profesionales, esta tÃ©cnica es clave para usar la IA de forma segura, comprensible y eficiente.

---

## ğŸ‘¨â€ğŸ’» Autor
**Lester DÃ¡vila**  
Participante del curso "IA Generativa â€“ IBM SkillsBuild", mÃ³dulo de prompting (junio 2025).

## ğŸ“„ Licencia
Este proyecto estÃ¡ licenciado bajo la Licencia MIT.  
Consulta el archivo [LICENSE](LICENSE) para mÃ¡s detalles.
